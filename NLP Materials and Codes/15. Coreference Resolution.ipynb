{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Coreference]((https://en.wikipedia.org/wiki/Coreference)) resolution is the task of finding all expressions that refer to the same entity in a text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Using Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T18:07:54.410646Z",
     "start_time": "2020-05-04T18:07:52.139180Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x2468621af28>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your usual SpaCy model (one of SpaCy English models)\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Add neural coref to SpaCy's pipe\n",
    "import neuralcoref\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T18:08:01.261813Z",
     "start_time": "2020-05-04T18:08:01.256825Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "examples = [\n",
    "    u'My sister has a dog and she loves him.',\n",
    "    u'My sister has a dog and she loves him. He is cute.',\n",
    "    u'My sister has a dog and she loves her.',\n",
    "    u'My brother has a dog and he loves her.',\n",
    "    u'Mary and Julie are sisters. They love chocolates.',\n",
    "    u'John and Mary are neighbours. She admires him because he works hard.',\n",
    "    u'X and Y are neighbours. She admires him because he works hard.',\n",
    "    u'The dog chased the cat. But it escaped.',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T18:08:05.386260Z",
     "start_time": "2020-05-04T18:08:05.379279Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def printMentions(doc):\n",
    "    print('\\nAll the \"mentions\" in the given text:')\n",
    "    for cluster in doc._.coref_clusters:\n",
    "        print(cluster.mentions)\n",
    "\n",
    "def printPronounReferences(doc):\n",
    "    print('\\nPronouns and their references:')\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'PRON' and token._.in_coref:\n",
    "            for cluster in token._.coref_clusters:\n",
    "                print(token.text + \" => \" + cluster.main.text)\n",
    "                \n",
    "def processDoc(text):\n",
    "    doc = nlp(text)\n",
    "    if doc._.has_coref:\n",
    "        print(\"Given text: \" + text)\n",
    "        printMentions(doc)\n",
    "        printPronounReferences(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T18:08:07.091878Z",
     "start_time": "2020-05-04T18:08:07.067482Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given text: My brother has a dog and he loves her.\n",
      "\n",
      "All the \"mentions\" in the given text:\n",
      "[My brother, he, her]\n",
      "\n",
      "Pronouns and their references:\n",
      "he => My brother\n",
      "her => My brother\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    processDoc(examples[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T16:32:25.083377Z",
     "start_time": "2020-05-04T16:32:25.063430Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[the party: [the party, They]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or\n",
    "# You're done. You can now use NeuralCoref as you usually manipulate a SpaCy document annotations.\n",
    "doc = nlp(u'Carol told Bobi to attend the party. They arrived together.')\n",
    "\n",
    "doc._.has_coref\n",
    "doc._.coref_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Using StanfordNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Steps:**\n",
    "1. Install java 64 bit (in cmd try java -d64 -version)\n",
    "2. Follow instructions from https://www.khalidalnajjar.com/setup-use-stanford-corenlp-server-python/\n",
    "    * Go to [link](https://stanfordnlp.github.io/CoreNLP/index.html#download) and install Standofrd CoreNLP\n",
    "    * Extract it in a folder in C drive.\n",
    "    * Run Stanford NLP Java Server\n",
    "    * **java -mx2g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -annotators \"tokenize,ssplit,pos,lemma,parse,sentiment\" -port 9000 -timeout 30000**\n",
    "    * Change ram size in -mx2g folder.\n",
    "3. \"CTRL-C\" command kills the server and releases the memory.\n",
    "4. [Link](https://stanfordnlp.github.io/CoreNLP/memory-time.html) for memory/time optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T17:53:19.118022Z",
     "start_time": "2020-05-04T17:53:18.665704Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T17:53:24.134937Z",
     "start_time": "2020-05-04T17:53:24.122968Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def resolve(corenlp_output):\n",
    "    \"\"\" Transfer the word form of the antecedent to its associated pronominal anaphor(s) \"\"\"\n",
    "    for coref in corenlp_output['corefs']:\n",
    "        mentions = corenlp_output['corefs'][coref]\n",
    "        antecedent = mentions[0]  # the antecedent is the first mention in the coreference chain\n",
    "        for j in range(1, len(mentions)):\n",
    "            mention = mentions[j]\n",
    "            if mention['type'] == 'PRONOMINAL':\n",
    "                # get the attributes of the target mention in the corresponding sentence\n",
    "                target_sentence = mention['sentNum']\n",
    "                target_token = mention['startIndex'] - 1\n",
    "                # transfer the antecedent's word form to the appropriate token in the sentence\n",
    "                corenlp_output['sentences'][target_sentence - 1]['tokens'][target_token]['word'] = antecedent['text']\n",
    "                \n",
    "def print_resolved(corenlp_output):\n",
    "    \"\"\" Print the \"resolved\" output \"\"\"\n",
    "    possessives = ['hers', 'his', 'their', 'theirs']\n",
    "    for sentence in corenlp_output['sentences']:\n",
    "        for token in sentence['tokens']:\n",
    "            output_word = token['word']\n",
    "            # check lemmas as well as tags for possessive pronouns in case of tagging errors\n",
    "            if token['lemma'] in possessives or token['pos'] == 'PRP$':\n",
    "                output_word += \"'s\"  # add the possessive morpheme\n",
    "            output_word += token['after']\n",
    "            print(output_word, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T17:54:01.983085Z",
     "start_time": "2020-05-04T17:53:25.740533Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Tom and Jane are good friends. They are cool. He knows a lot of things and so does she. His car is red, but hers is blue. It is older than hers. The big cat ate its dinner.\n",
      "Resolved: Tom and Jane are good friends. Tom and Jane are cool. Tom knows a lot of things and so does Jane. Tom's car is red, but Jane's is blue. His car is older than Jane's. The big cat ate His car's dinner."
     ]
    }
   ],
   "source": [
    "text = \"Tom and Jane are good friends. They are cool. He knows a lot of things and so does she. His car is red, but \" \\\n",
    "       \"hers is blue. It is older than hers. The big cat ate its dinner.\"\n",
    "\n",
    "output = nlp.annotate(text, properties= {'annotators':'dcoref','outputFormat':'json','ner.useSUTime':'false'})\n",
    "\n",
    "resolve(output)\n",
    "\n",
    "print('Original:', text)\n",
    "print('Resolved: ', end='')\n",
    "print_resolved(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford Vs. Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:03:00.936949Z",
     "start_time": "2020-05-05T10:03:00.883097Z"
    }
   },
   "outputs": [],
   "source": [
    "text = [\"The music was so loud that it couldn't be enjoyed.\",\n",
    "        \"Our neighbors dislike the music. If they are angry, the cops will show up soon.\",\n",
    "        \"If they are angry about the music, the neighbors will call the cops.\",\n",
    "        \"Despite her difficulty, Wilma came to understand the point.\",\n",
    "        \"Carol told Bobi to attend the party. They arrived together.\",\n",
    "        \"When Carol helps Bob and Bob helps Carol, they can accomplish any task.\",\n",
    "        \"The project leader is refusing to help. The jerk thinks only of himself.\",\n",
    "        \"Some of our colleagues are going to be supportive. These kinds of people will earn our gratitude.\",\n",
    "        \"The trophy would not fit in the brown suitcase because it was too big.\"]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T18:05:56.150333Z",
     "start_time": "2020-05-04T18:05:54.829425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: The music was so loud that it couldn't be enjoyed.\n",
      "Resolved: The music was so loud that The music couldn't be enjoyed.\n",
      "Original: Our neighbors dislike the music. If they are angry, the cops will show up soon.\n",
      "Resolved: Our's neighbors dislike the music. If Our neighbors are angry, the cops will show up soon.\n",
      "Original: If they are angry about the music, the neighbors will call the cops.\n",
      "Resolved: If they are angry about the music, the neighbors will call the cops.\n",
      "Original: Despite her difficulty, Wilma came to understand the point.\n",
      "Resolved: Despite her's difficulty, Wilma came to understand the point.\n",
      "Original: Carol told Bobi to attend the party. They arrived together.\n",
      "Resolved: Carol told Bobi to attend the party. They arrived together.\n",
      "Original: When Carol helps Bob and Bob helps Carol, they can accomplish any task.\n",
      "Resolved: When Carol helps Bob and Bob helps Carol, Bob and Bob can accomplish any task.\n",
      "Original: The project leader is refusing to help. The jerk thinks only of himself.\n",
      "Resolved: The project leader is refusing to help. The jerk thinks only of The jerk.\n",
      "Original: Some of our colleagues are going to be supportive. These kinds of people will earn our gratitude.\n",
      "Resolved: Some of our's colleagues are going to be supportive. These kinds of people will earn our's gratitude.\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(text)):\n",
    "    output = nlp.annotate(text[i], properties= {'annotators':'dcoref','outputFormat':'json','ner.useSUTime':'false'})\n",
    "\n",
    "    resolve(output)\n",
    "\n",
    "    print('Original:', text[i])\n",
    "    print('Resolved: ', end='')\n",
    "    print_resolved(output)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:03:06.759382Z",
     "start_time": "2020-05-05T10:03:05.929604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given text: The music was so loud that it couldn't be enjoyed.\n",
      "\n",
      "All the \"mentions\" in the given text:\n",
      "[The music, it]\n",
      "\n",
      "Pronouns and their references:\n",
      "it => The music\n",
      "\n",
      "Given text: Our neighbors dislike the music. If they are angry, the cops will show up soon.\n",
      "\n",
      "All the \"mentions\" in the given text:\n",
      "[Our neighbors, they]\n",
      "\n",
      "Pronouns and their references:\n",
      "they => Our neighbors\n",
      "\n",
      "\n",
      "Given text: Despite her difficulty, Wilma came to understand the point.\n",
      "\n",
      "All the \"mentions\" in the given text:\n",
      "[her, Wilma]\n",
      "\n",
      "Pronouns and their references:\n",
      "\n",
      "Given text: Carol told Bobi to attend the party. They arrived together.\n",
      "\n",
      "All the \"mentions\" in the given text:\n",
      "[the party, They]\n",
      "\n",
      "Pronouns and their references:\n",
      "They => the party\n",
      "\n",
      "Given text: When Carol helps Bob and Bob helps Carol, they can accomplish any task.\n",
      "\n",
      "All the \"mentions\" in the given text:\n",
      "[Carol, Carol]\n",
      "[Bob, Bob]\n",
      "[Bob and Bob, they]\n",
      "\n",
      "Pronouns and their references:\n",
      "they => Bob and Bob\n",
      "\n",
      "Given text: The project leader is refusing to help. The jerk thinks only of himself.\n",
      "\n",
      "All the \"mentions\" in the given text:\n",
      "[The jerk, himself]\n",
      "\n",
      "Pronouns and their references:\n",
      "himself => The jerk\n",
      "\n",
      "Given text: Some of our colleagues are going to be supportive. These kinds of people will earn our gratitude.\n",
      "\n",
      "All the \"mentions\" in the given text:\n",
      "[our, our]\n",
      "\n",
      "Pronouns and their references:\n",
      "\n",
      "Given text: The trophy would not fit in the brown suitcase because it was too big.\n",
      "\n",
      "All the \"mentions\" in the given text:\n",
      "[The trophy, it]\n",
      "\n",
      "Pronouns and their references:\n",
      "it => The trophy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(text)):\n",
    "    if __name__ == \"__main__\":\n",
    "        processDoc(text[i])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T17:57:30.296757Z",
     "start_time": "2020-05-06T17:57:17.426326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "Losses {'ner': 38.61012762784958}\n",
      "Losses {'ner': 17.51923118904233}\n",
      "Losses {'ner': 8.510706414787819}\n",
      "Losses {'ner': 9.275895185564423}\n",
      "Losses {'ner': 8.27842292211426}\n",
      "Losses {'ner': 3.285048616497079}\n",
      "Losses {'ner': 2.629565456355863}\n",
      "Losses {'ner': 0.5143076098867678}\n",
      "Losses {'ner': 0.14073449907551744}\n",
      "Losses {'ner': 0.013571078565430711}\n",
      "Losses {'ner': 0.0005333663947689162}\n",
      "Losses {'ner': 0.0003102885546442968}\n",
      "Losses {'ner': 1.4933599401414127e-05}\n",
      "Losses {'ner': 0.008191097285029036}\n",
      "Losses {'ner': 3.778854443138536e-06}\n",
      "Losses {'ner': 9.192545628506831e-07}\n",
      "Losses {'ner': 8.910108077462803e-05}\n",
      "Losses {'ner': 0.003805166581499559}\n",
      "Losses {'ner': 0.0007198828174248596}\n",
      "Losses {'ner': 1.2225052562323564e-07}\n",
      "Losses {'ner': 6.200159303778063e-07}\n",
      "Losses {'ner': 3.2238199033687577e-06}\n",
      "Losses {'ner': 5.50518720640107e-08}\n",
      "Losses {'ner': 3.573447064233407e-08}\n",
      "Losses {'ner': 3.775577714707288e-09}\n",
      "Losses {'ner': 0.0006222276868892166}\n",
      "Losses {'ner': 7.201473048519221e-08}\n",
      "Losses {'ner': 1.5301112793252792e-08}\n",
      "Losses {'ner': 9.426414858052819e-05}\n",
      "Losses {'ner': 1.8786656765210078e-08}\n",
      "Entities in 'Do you like horses?'\n",
      "ANIMAL horses\n",
      "Saved model to None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'Path' has no attribute 'cmd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-b5c67c1591cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-43-b5c67c1591cd>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(model, new_model_name, output_dir, n_iter)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;31m# test the saved model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     \u001b[0mnlp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;31m# Check the classes have loaded back consistently\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'Path' has no attribute 'cmd'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf8\n",
    "\"\"\"Example of training an additional entity type\n",
    "\n",
    "This script shows how to add a new entity type to an existing pretrained NER\n",
    "model. To keep the example short and simple, only four sentences are provided\n",
    "as examples. In practice, you'll need many more — a few hundred would be a\n",
    "good start. You will also likely need to mix in examples of other entity\n",
    "types, which might be obtained by running the entity recognizer over unlabelled\n",
    "sentences, and adding their annotations to the training set.\n",
    "\n",
    "The actual training is performed by looping over the examples, and calling\n",
    "`nlp.entity.update()`. The `update()` method steps through the words of the\n",
    "input. At each word, it makes a prediction. It then consults the annotations\n",
    "provided on the GoldParse instance, to see whether it was right. If it was\n",
    "wrong, it adjusts its weights so that the correct action will score higher\n",
    "next time.\n",
    "\n",
    "After training your model, you can save it to a directory. We recommend\n",
    "wrapping models as Python packages, for ease of deployment.\n",
    "\n",
    "For more details, see the documentation:\n",
    "* Training: https://spacy.io/usage/training\n",
    "* NER: https://spacy.io/usage/linguistic-features#named-entities\n",
    "\n",
    "Compatible with: spaCy v2.1.0+\n",
    "Last tested with: v2.1.0\n",
    "\"\"\"\n",
    "from __future__ import unicode_literals, print_function\n",
    "\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "\n",
    "# new entity label\n",
    "LABEL = \"ANIMAL\"\n",
    "\n",
    "# training data\n",
    "# Note: If you're using an existing model, make sure to mix in examples of\n",
    "# other entity types that spaCy correctly recognized before. Otherwise, your\n",
    "# model might learn the new type, but \"forget\" what it previously knew.\n",
    "# https://explosion.ai/blog/pseudo-rehearsal-catastrophic-forgetting\n",
    "TRAIN_DATA = [\n",
    "    (\n",
    "        \"Horses are too tall and they pretend to care about your feelings\",\n",
    "        {\"entities\": [(0, 6, LABEL)]},\n",
    "    ),\n",
    "    (\"Do they bite?\", {\"entities\": []}),\n",
    "    (\n",
    "        \"horses are too tall and they pretend to care about your feelings\",\n",
    "        {\"entities\": [(0, 6, LABEL)]},\n",
    "    ),\n",
    "    (\"horses pretend to care about your feelings\", {\"entities\": [(0, 6, LABEL)]}),\n",
    "    (\n",
    "        \"they pretend to care about your feelings, those horses\",\n",
    "        {\"entities\": [(48, 54, LABEL)]},\n",
    "    ),\n",
    "    (\"horses?\", {\"entities\": [(0, 6, LABEL)]}),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "model=(\"Model name. Defaults to blank 'en' model.\", \"option\", \"m\", str),\n",
    "new_model_name=(\"New model name for model meta.\", \"option\", \"nm\", str),\n",
    "output_dir=(\"Optional output directory\", \"option\", \"o\", Path),\n",
    "n_iter=(\"Number of training iterations\", \"option\", \"n\", int),\n",
    "\n",
    "def main(model=None, new_model_name=\"animal\", output_dir=None, n_iter=30):\n",
    "    \"\"\"Set up the pipeline and entity recognizer, and train the new entity.\"\"\"\n",
    "    random.seed(0)\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "    # Add entity recognizer to model if it's not in the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner)\n",
    "    # otherwise, get it, so we can add labels to it\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "    ner.add_label(LABEL)  # add new entity label to entity recognizer\n",
    "    # Adding extraneous labels shouldn't mess anything up\n",
    "    ner.add_label(\"VEGETABLE\")\n",
    "    if model is None:\n",
    "        optimizer = nlp.begin_training()\n",
    "    else:\n",
    "        optimizer = nlp.resume_training()\n",
    "    move_names = list(ner.move_names)\n",
    "    # get names of other pipes to disable them during training\n",
    "    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        sizes = compounding(1.0, 4.0, 1.001)\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            batches = minibatch(TRAIN_DATA, size=sizes)\n",
    "            losses = {}\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
    "            print(\"Losses\", losses)\n",
    "\n",
    "    # test the trained model\n",
    "    test_text = \"Do you like horses?\"\n",
    "    doc = nlp(test_text)\n",
    "    print(\"Entities in '%s'\" % test_text)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.label_, ent.text)\n",
    "\n",
    "    # save model to output directory\n",
    "    nlp.meta[\"name\"] = new_model_name  # rename model\n",
    "    nlp.to_disk('C:/Users/saurabhkumar9/1. NLP Practicum Materials')\n",
    "    print(\"Saved model to\", output_dir)\n",
    "\n",
    "    # test the saved model\n",
    "    nlp2 = spacy.load(Path.cmd())\n",
    "    \n",
    "    # Check the classes have loaded back consistently\n",
    "    assert nlp2.get_pipe(\"ner\").move_names == move_names\n",
    "    doc2 = nlp2(test_text)\n",
    "    for ent in doc2.ents:\n",
    "        print(ent.label_, ent.text)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T18:01:11.106934Z",
     "start_time": "2020-05-06T18:01:11.101949Z"
    }
   },
   "outputs": [],
   "source": [
    "examples = [\n",
    "    ('Who is Shaka Khan?',\n",
    "     [(7, 17, 'PERSON')]),\n",
    "    ('I like London and Berlin.',\n",
    "     [(7, 13, 'LOC'), (18, 24, 'LOC')])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T18:06:06.390295Z",
     "start_time": "2020-05-06T18:06:06.383309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uas': 0.0,\n",
       " 'las': 0.0,\n",
       " 'ents_p': 0.0,\n",
       " 'ents_r': 0.0,\n",
       " 'ents_f': 0.0,\n",
       " 'tags_acc': 0.0,\n",
       " 'token_acc': 100.0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "P.Loss : Parser loss\n",
    "N.Loss : NER loss \n",
    "UAS : Unlabelled attachment score for parser \n",
    "NER P. : NER Precision on development data\n",
    "NER R. : NER recall on development data\n",
    "NER F. : NER F on development data\n",
    "Tag % :Tag accuracy on development data \n",
    "T Token % : Tokenization accuracy on development data (irrelevant if you use the .iob format, which prevents you from learning from incorrectly tokenized text).\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "spyder",
   "language": "python",
   "name": "spyder"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
