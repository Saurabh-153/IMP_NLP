{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "spaCy is an advanced modern library for Natural Language Processing developed by Matthew Honnibal and Ines Montani. It is designed to be industrial grade but open source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T16:28:45.835561Z",
     "start_time": "2020-07-27T16:28:38.322926Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U spacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "spaCy comes with pretrained NLP models that can perform most common NLP tasks, such as tokenization, parts of speech (POS) tagging, named entity recognition (NER), lemmatization, transforming to word vectors etc.\n",
    "\n",
    "If you are dealing with a particular language, you can load the spacy model specific to the language using spacy.load() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T16:29:18.792734Z",
     "start_time": "2020-07-27T16:29:16.842785Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saurabhkumar9\\AppData\\Local\\Continuum\\anaconda2\\envs\\nlp\\lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.0) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x28a94a13588>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load small english model: https://spacy.io/models\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This returns a Language object that comes ready with multiple built-in capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## The Doc object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now, let us say you have your text data in a string. What can be done to understand the structure of the text?\n",
    "\n",
    "First, call the loaded nlp object on the text. It should return a processed Doc object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T16:30:39.563093Z",
     "start_time": "2020-07-27T16:30:39.531668Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse text through the `nlp` model\n",
    "my_text = \"\"\"The economic situation of the country is on edge , as the stock \n",
    "market crashed causing loss of millions. Citizens who had their main investment \n",
    "in the share-market are facing a great loss. Many companies might lay off \n",
    "thousands of people to reduce labor cost\"\"\"\n",
    "\n",
    "my_doc = nlp(my_text)\n",
    "type(my_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The output is a Doc object.\n",
    "\n",
    "But, what exactly is a Doc object ?\n",
    "\n",
    "It is a sequence of tokens that contains not just the original text but all the results produced by the spaCy model after processing the text. Useful information such as the lemma of the text, whether it is a stop word or not, named entities, the word vector of the text and so on are pre-computed and readily stored in the Doc object.\n",
    "\n",
    "The good thing is that you have complete control on what information needs to be pre-computed and customized. We will see all of that shortly.\n",
    "\n",
    "Also, though the text gets split into tokens, no information of the original text is actually lost.\n",
    "\n",
    "What is a Token?\n",
    "\n",
    "Tokens are individual text entities that make up the text. Typically a token can be the words, punctuation, spaces, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tokenization with spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**What is Tokenization?**\n",
    "\n",
    "Tokenization is the process of converting a text into smaller sub-texts, based on certain predefined rules. For example, sentences are tokenized to words (and punctuation optionally). And paragraphs into sentences, depending on the context.\n",
    "\n",
    "This is typically the first step for NLP tasks like text classification, sentiment analysis, etc.\n",
    "\n",
    "Each token in spacy has different attributes that tell us a great deal of information.\n",
    "\n",
    "Such as, if the token is a punctuation, what part-of-speech (POS) is it, what is the lemma of the word etc. This article will cover everything from A-Z.\n",
    "\n",
    "Let’s see the token texts on my_doc. The string which the token represents can be accessed through the token.text attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T16:34:00.404925Z",
     "start_time": "2020-07-27T16:34:00.397944Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "economic\n",
      "situation\n",
      "of\n",
      "the\n",
      "country\n",
      "is\n",
      "on\n",
      "edge\n",
      ",\n",
      "as\n",
      "the\n",
      "stock\n",
      "\n",
      "\n",
      "market\n",
      "crashed\n",
      "causing\n",
      "loss\n",
      "of\n",
      "millions\n",
      ".\n",
      "Citizens\n",
      "who\n",
      "had\n",
      "their\n",
      "main\n",
      "investment\n",
      "\n",
      "\n",
      "in\n",
      "the\n",
      "share\n",
      "-\n",
      "market\n",
      "are\n",
      "facing\n",
      "a\n",
      "great\n",
      "loss\n",
      ".\n",
      "Many\n",
      "companies\n",
      "might\n",
      "lay\n",
      "off\n",
      "\n",
      "\n",
      "thousands\n",
      "of\n",
      "people\n",
      "to\n",
      "reduce\n",
      "labor\n",
      "cost\n"
     ]
    }
   ],
   "source": [
    "# Printing the tokens of a doc\n",
    "for token in my_doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The above tokens contain punctuation and common words like “a”, ” the”, “was”, etc. These do not add any value to the meaning of your text. They are called stop words.\n",
    "\n",
    "Let’s clean it up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Text-Preprocessing with spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As mentioned in the last section, there is ‘noise’ in the tokens. The words such as ‘the’, ‘was’, ‘it’ etc are very common and are referred as ‘stop words’.\n",
    "\n",
    "Besides, you have punctuation like commas, brackets, full stop and some extra white spaces too. The process of removing noise from the doc is called **Text Cleaning or Preprocessing.**\n",
    "\n",
    "**What is the need for Text Preprocessing ?**\n",
    "\n",
    "The outcome of the NLP task you perform, be it classification, finding sentiments, topic modeling etc, the quality of the output depends heavily on the quality of the input text used.\n",
    "\n",
    "Stop words and punctuation usually (not always) don’t add value to the meaning of the text and can potentially impact the outcome. To avoid this, its might make sense to remove them and clean the text of unwanted characters can reduce the size of the corpus.\n",
    "\n",
    "**How to identify and remove the stopwords and punctuation?**\n",
    "\n",
    "The tokens in spacy have attributes which will help you identify if it is a stop word or not.\n",
    "\n",
    "The token.is_stop attribute tells you that. Likewise, token.is_punct and token.is_space tell you if a token is a punctuation and white space respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T16:36:05.359692Z",
     "start_time": "2020-07-27T16:36:05.349267Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The -- True --- False\n",
      "economic -- False --- False\n",
      "situation -- False --- False\n",
      "of -- True --- False\n",
      "the -- True --- False\n",
      "country -- False --- False\n",
      "is -- True --- False\n",
      "on -- True --- False\n",
      "edge -- False --- False\n",
      ", -- False --- True\n",
      "as -- True --- False\n",
      "the -- True --- False\n",
      "stock -- False --- False\n",
      "\n",
      " -- False --- False\n",
      "market -- False --- False\n",
      "crashed -- False --- False\n",
      "causing -- False --- False\n",
      "loss -- False --- False\n",
      "of -- True --- False\n",
      "millions -- False --- False\n",
      ". -- False --- True\n",
      "Citizens -- False --- False\n",
      "who -- True --- False\n",
      "had -- True --- False\n",
      "their -- True --- False\n",
      "main -- False --- False\n",
      "investment -- False --- False\n",
      "\n",
      " -- False --- False\n",
      "in -- True --- False\n",
      "the -- True --- False\n",
      "share -- False --- False\n",
      "- -- False --- True\n",
      "market -- False --- False\n",
      "are -- True --- False\n",
      "facing -- False --- False\n",
      "a -- True --- False\n",
      "great -- False --- False\n",
      "loss -- False --- False\n",
      ". -- False --- True\n",
      "Many -- True --- False\n",
      "companies -- False --- False\n",
      "might -- True --- False\n",
      "lay -- False --- False\n",
      "off -- True --- False\n",
      "\n",
      " -- False --- False\n",
      "thousands -- False --- False\n",
      "of -- True --- False\n",
      "people -- False --- False\n",
      "to -- True --- False\n",
      "reduce -- False --- False\n",
      "labor -- False --- False\n",
      "cost -- False --- False\n"
     ]
    }
   ],
   "source": [
    "# Printing tokens and boolean values stored in different attributes\n",
    "for token in my_doc:\n",
    "    print(token.text,'--',token.is_stop,'---',token.is_punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using this information, let’s remove the stopwords and punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T16:36:48.460076Z",
     "start_time": "2020-07-27T16:36:48.453063Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "economic\n",
      "situation\n",
      "country\n",
      "edge\n",
      "stock\n",
      "\n",
      "\n",
      "market\n",
      "crashed\n",
      "causing\n",
      "loss\n",
      "millions\n",
      "Citizens\n",
      "main\n",
      "investment\n",
      "\n",
      "\n",
      "share\n",
      "market\n",
      "facing\n",
      "great\n",
      "loss\n",
      "companies\n",
      "lay\n",
      "\n",
      "\n",
      "thousands\n",
      "people\n",
      "reduce\n",
      "labor\n",
      "cost\n"
     ]
    }
   ],
   "source": [
    "# Removing StopWords and punctuations\n",
    "my_doc_cleaned = [token for token in my_doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "for token in my_doc_cleaned:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can now see that the cleaned doc has only tokens that contribute to meaning in some way.\n",
    "\n",
    "Also , the computational costs decreases by a great amount due to reduce in the number of tokens. In order to grasp the effect of Preprocessing on large text data , you can excecute the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T16:37:56.393947Z",
     "start_time": "2020-07-27T16:37:55.852392Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before PreProcessing n_Tokens:  1626\n",
      "After PreProcessing n_Tokens:  744\n"
     ]
    }
   ],
   "source": [
    "# Reading a huge text data on robotics into a spacy doc\n",
    "robotics_data= \"\"\"Robotics is an interdisciplinary research area at the interface of computer science and engineering. Robotics involvesdesign, construction, operation, and use of robots. The goal of robotics is to design intelligent machines that can help and assist humans in their day-to-day lives and keep everyone safe. Robotics draws on the achievement of information engineering, computer engineering, mechanical engineering, electronic engineering and others.Robotics develops machines that can substitute for humans and replicate human actions. Robots can be used in many situations and for lots of purposes, but today many are used in dangerous environments(including inspection of radioactive materials, bomb detection and deactivation), manufacturing processes, or where humans cannot survive (e.g. in space, underwater, in high heat, and clean up and containment of hazardousmaterials and radiation). Robots can take on any form but some are made to resemble humans in appearance. This is said to help in the acceptance of a robot in \n",
    "certain replicative behaviors usually performed by people. Such robots attempt to replicate walking, lifting, speech, cognition, or any other human activity. Many of todays robots are inspired by nature, contributing to the field of bio-inspired \n",
    "robotics.The concept of creating machines that can operate autonomously dates back to classical times, but research into the functionality and potential uses of robots did not grow substantially until the 20th century. Throughout history, it has been frequently assumed by various scholars, inventors, engineers, and technicians that robots will one day be able to mimic human behavior and manage tasks in a human-like fashion. Today, robotics is a rapidly growing field, as technological advances continue; researching, designing, and building new robots serve various practical purposes, whether domestically, commercially, or militarily. Many robots are built to do jobs that are hazardous to people, such as defusing bombs, finding survivors in unstable ruins, and exploring mines and shipwrecks. Robotics is also used in STEM (science, technology, engineering, and mathematics) as a teaching aid. The advent of nanorobots, microscopic robots that can be injected into the human body, could revolutionize medicine and human health.Robotics is a branch of engineering that involves the conception, design, manufacture, and operation of robots. This field overlaps with computer engineering, computer science (especially artificial intelligence), electronics, mechatronics, nanotechnology and bioengineering.The word robotics was derived from the word robot, which was introduced to the public by Czech writer Karel Capek in his play R.U.R. (Rossums Universal Robots), whichwas published in 1920. The word robot comes from the Slavic word robota, which means slave/servant. The play begins in a factory that makes artificial people called robots, creatures who can be mistaken for humans – very similar to the modern ideas of androids. Karel Capek himself did not coin the word. He wrote a short letter in reference to an etymology in the \n",
    "Oxford English Dictionary in which he named his brother Josef Capek as its actual \n",
    "originator.According to the Oxford English Dictionary, the word robotics was first \n",
    "used in print by Isaac Asimov, in his science fiction short story \"Liar!\", \n",
    "published in May 1941 in Astounding Science Fiction. Asimov was unaware that he \n",
    "was coining the term  since the science and technology of electrical devices is \n",
    "electronics, he assumed robotics already referred to the science and technology \n",
    "of robots. In some of Asimovs other works, he states that the first use of the \n",
    "word robotics was in his short story Runaround (Astounding Science Fiction, March \n",
    "1942) where he introduced his concept of The Three Laws of Robotics. However, \n",
    "the original publication of \"Liar!\" predates that of \"Runaround\" by ten months, \n",
    "so the former is generally cited as the words origin.There are many types of robots; \n",
    "they are used in many different environments and for many different uses. Although \n",
    "being very diverse in application and form, they all share three basic similarities \n",
    "when it comes to their construction:Robots all have some kind of mechanical construction, a frame, form or shape designed to achieve a particular task. For example, a robot designed to travel across heavy dirt or mud, might use caterpillar tracks. The mechanical aspect is mostly the creators solution to completing the assigned task and dealing with the physics of the environment around it. Form follows function.Robots have electrical components which power and control the machinery. For example, the robot with caterpillar tracks would need some kind of power to move the tracker treads. That power comes in the form of electricity, which will have to travel through a wire and originate from a battery, a basic electrical circuit. Even petrol powered machines that get their power mainly from petrol still require an electric current to start the combustion process which is why most petrol powered machines like cars, have batteries. The electrical aspect of robots is used for movement (through motors), sensing (where electrical signals are used to measure things like heat, sound, position, and energy status) and operation (robots need some level of electrical energy supplied to their motors and sensors in order to activate and perform basic operations) All robots contain some level of computer programming code. A program is how a robot decides when or how to do something. In the caterpillar track example, a robot that needs to move across a muddy road may have the correct mechanical construction and receive the correct amount of power from its battery, but would not go anywhere without a program telling it to move. Programs are the core essence of a robot, it could have excellent mechanical and electrical construction, but if its program is poorly constructed its performance will be very poor (or it may not perform at all). There are three different types of robotic programs: remote control, artificial intelligence and hybrid. A robot with remote control programing has a preexisting set of commands that it will only perform if and when it receives a signal from a control source, typically a human being with a remote control. It is perhaps more appropriate to view devices controlled primarily by human commands as falling in the discipline of automation rather than robotics. Robots that use artificial intelligence interact with their environment on their own without a control source, and can determine reactions to objects and problems they encounter using their preexisting programming. Hybrid is a form of programming that incorporates both AI and RC functions.As more and more robots are designed for specific tasks this method of classification becomes more relevant. For example, many robots are designed for assembly work, which may not be readily adaptable for other applications. They are termed as \"assembly robots\". For seam welding, some suppliers provide complete welding systems with the robot i.e. the welding equipment along with other material handling facilities like turntables, etc. as an integrated unit. Such an integrated robotic system is called a \"welding robot\" even though its discrete manipulator unit could be adapted to a variety of tasks. Some robots are specifically designed for heavy load manipulation, and are labeled as \"heavy-duty robots\".one or two wheels. These can have certain advantages such as greater efficiency and reduced parts, as well as allowing a robot to navigate in confined places that a four-wheeled robot would not be able to.Two-wheeled balancing robots Balancing robots generally use a gyroscope to detect how much a robot is falling and then drive the wheels proportionally in the same direction, to counterbalance the fall at hundreds of times per second, based on the dynamics of an inverted pendulum.[71] Many different balancing robots have been designed.[72] While the Segway is not commonly thought of as a robot, it can be thought of as a component of a robot, when used as such Segway refer to them as RMP (Robotic Mobility Platform). An example of this use has been as NASA Robonaut that has been mounted on a Segway.One-wheeled balancing robots Main article: Self-balancing unicycle A one-wheeled balancing robot is an extension of a two-wheeled balancing robot so that it can move in any 2D direction using a round ball as its only wheel. Several one-wheeled balancing robots have been designed recently, such as Carnegie Mellon Universitys \"Ballbot\" that is the approximate height and width of a person, and Tohoku Gakuin University BallIP Because of the long, thin shape and ability to maneuver in tight spaces, they have the potential to function better than other robots in environments with people\n",
    "\"\"\"\n",
    "\n",
    "# Pass the Text to Model\n",
    "robotics_doc = nlp(robotics_data)\n",
    "\n",
    "print('Before PreProcessing n_Tokens: ', len(robotics_doc))\n",
    "\n",
    "# Removing stopwords and punctuation from the doc.\n",
    "robotics_doc=[token for token in robotics_doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "print('After PreProcessing n_Tokens: ', len(robotics_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "More than half of the tokens are removed. Makes the processing faster and meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Have a look at these words: **“played”, “playing”, “plays”, “play”.**\n",
    "\n",
    "These words are not entirely unique, as they all basically refer to the root word: “play”. Very often, while trying to interpret the meaning of the text using NLP, you will be concerned about the root meaning and not the tense.\n",
    "\n",
    "For algorithms that work based on the number of occurrences of the words, having multiple forms of the same word will reduce the number of counts for the root word, which is ‘play’ in this case.\n",
    "\n",
    "Hence, counting “played” and “playing” as different tokens will not help.\n",
    "\n",
    "**Lemmatization is the method of converting a token to it’s root/base form.**\n",
    "\n",
    "Fortunately, spaCy provides a very easy and robust solution for this and is considered as one of the optimal implementations.\n",
    "\n",
    "After you’ve formed the Document object (by using nlp()), you can access the root form of every token through Token.lemma_ attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T16:39:36.121267Z",
     "start_time": "2020-07-27T16:39:36.096334Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-PRON-\n",
      "play\n",
      "chess\n",
      "against\n",
      "rita\n",
      "-PRON-\n",
      "like\n",
      "play\n",
      "chess\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Lemmatizing the tokens of a doc\n",
    "text='she played chess against rita she likes playing chess.'\n",
    "\n",
    "doc=nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This method also prints ‘PRON’ when it encounters a pronoun as shown above. You might have to explicitly handle them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strings to Hashes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are aware that whenever you create a doc , the words of the doc are stored in the Vocab.\n",
    "\n",
    "Also, consider you have about 1000 text documents each having information about various clothing items of different brands. The chances are, the words “shirt” and “pants” are going to be very common. Each time the word “shirt” occurs , if spaCy were to store the exact string , you’ll end up losing huge memory space.\n",
    "\n",
    "But this doesn’t happen. Why ?\n",
    "\n",
    "spaCy hashes or converts each string to a unique ID that is stored in the StringStore.\n",
    "\n",
    "But, what is StringStore?\n",
    "\n",
    "It’s a dictionary mapping of hash values to strings, for example 10543432924755684266 –> box\n",
    "\n",
    "You can print the hash value if you know the string and vice-versa. This is contained in nlp.vocab.strings as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
